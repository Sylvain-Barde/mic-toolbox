{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIC Demo 1 - Basic steps for measurement\n",
    "\n",
    "This simple demonstration of the MIC toolbox uses two simulated bivariate VAR(2) models from the [\"Macroeconomic simulation comparison with a multivariate extension of the Markov Information Criterion\"](https://www.kent.ac.uk/economics/documents/research/papers/2019/1908.pdf) paper. These are the first two settings from the VAR validation exercises. The two simulated datasets are located in `data/model_1.txt` and `data/model_2.txt`. In addition this, one of these two models has been used to generated an 'empirical' dataset `data/emp_dat.txt`. The purpose of the demonstration is to show how to run the MIC and see if we can figure out which of models 1 or 2 is the true model.\n",
    "\n",
    "The purpose of this first part is to outline the individual steps required to obtain a MIC measurement on a single variable in a multivariate system. As a full multivariate measurment requires several runs of the algorithms, this is best done in parallel, which will be covered in the second demonstration notebook.\n",
    "\n",
    "We start with the setup, including the toolbox import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "import mic.toolbox as mt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 0 - Discretising the data\n",
    "\n",
    "The first task that needs to be done is to discretise the two variables in the system (denoted $x^1$ and $x^2$). In order to do so, we need to provide the following information:\n",
    "- `lb` and `ub` : Bounds to the range of variation. \n",
    "- `r_vec` : Binary discretisation resolution of the variables\n",
    "- `hp_bit_vec` : High priority bits - Number of bits to prioritise in the permutation\n",
    "\n",
    "We can then call the binary quantisation function in the toolbox, `mt.bin_quant()`, and look at the result of the discretisation diagnostics to ensure that settings above are chosen so that the discretisation error is i.i.d uniformly distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------+\n",
      "|            Quantization diagnostics             |\n",
      "+-------------------------------------------------+\n",
      " N° of observations:       1000\n",
      "\n",
      " Var N°:             1       2\n",
      " Lower bound:    -10.000 -10.000\n",
      " Upper bound:     10.000  10.000\n",
      " Min obs.:        -5.259  -4.709\n",
      " Max obs.:         6.160   4.381\n",
      " Out of bounds:        0       0\n",
      " Resolution:           7       7\n",
      " Standard dev.:    1.737   1.580\n",
      " Discr. unit:      0.156   0.156\n",
      "\n",
      " Signal-to-Noise ratio for quantisation (in dB):\n",
      " Var N°:             1       2\n",
      " Theoretical:     31.710  30.886\n",
      " Effective:       25.748  24.540\n",
      "\n",
      "+-------------------------------------------------+\n",
      " Kolmogorov-Smirnov test for uniformity\n",
      " H0: Distribution of errors is uniform\n",
      "\n",
      " Var N°:             1       2\n",
      " KS statistic:     0.016   0.059\n",
      " P-value:          0.999   0.059\n",
      "\n",
      "+-------------------------------------------------+\n",
      " Ljung-Box tests for autocorrelation of errors\n",
      " H0: The errors are independently distributed\n",
      "\n",
      " Critical value (Chi-sq, 7 df):       14.067\n",
      "\n",
      " Var N°:             1       2\n",
      " LB statistic:     2.243   5.252\n",
      " P-value:          0.945   0.629\n",
      "\n",
      "+-------------------------------------------------+\n",
      " Spearman correlation of error with digitised data\n",
      " H0: Quantisation errors not correlated with data\n",
      "\n",
      " Var N°:             1       2\n",
      " Correlation:     -0.025  -0.007\n",
      " P-value:          0.435   0.818\n",
      "\n",
      "+-------------------------------------------------+\n",
      "\n",
      " Correlation of high priority bits with raw data:\n",
      " Variable 1:  0.9865\n",
      " Variable 2:  0.9832\n"
     ]
    }
   ],
   "source": [
    "lb = [-10,-10]\n",
    "ub = [ 10, 10]\n",
    "r_vec = [7,7]\n",
    "hp_bit_vec = [3,3]\n",
    "\n",
    "# Load 'empirical' data \n",
    "path = 'data/emp_data.txt'\n",
    "emp_data = np.loadtxt(path, delimiter=\"\\t\") \n",
    "\n",
    "# Pick first replication (columns 1 and 2) - just as an example\n",
    "dat = emp_data[:,0:2]\n",
    "\n",
    "# Run the discretisation tests (displays are active by passing any string other than 'notests' or 'nodisplay')\n",
    "data_struct_emp = mt.bin_quant(dat,lb,ub,r_vec,'')\n",
    "\n",
    "# Check the correlation of the high-priority bits (example of 'notests' here)\n",
    "data_struct_hp = mt.bin_quant(dat,lb,ub,hp_bit_vec,'notests')\n",
    "dat_bin = data_struct_hp['binary_data']\n",
    "hp_dat = dat - np.asarray(dat_bin.errors)\n",
    "\n",
    "print('\\n Correlation of high priority bits with raw data:')\n",
    "for n in range(2):\n",
    "    corr = pearsonr(dat[:,n],hp_dat[:,n])\n",
    "    print(' Variable {:1d}: {:7.4f}'.format(n+1,corr[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that under the settings picked above, the quantisation errors for both series are indeed uniformly distributed (KS test not rejected), independent (LB test is not rejected) and the errors are not correlated with the discretisation levels. Furthermore, a discretisation using only the first three bits of each variable (the 'high priority bits') already has a 98% correlation with the raw data. This suggests that the settings are appropriate for the analysis.\n",
    "\n",
    "### Stage 1 - learning model probabilities from the data\n",
    "\n",
    "The important parameters to choose at this stage relate to the size of the tree that we want to build with the simulated data. The parameters of interest are:\n",
    "- `mem` : the maximum amount of nodes we can initialise. As trees tend to be sparse, this does not have to match the theoretical number of the trees $2^D$.\n",
    "- `d`: maximum depth of the context trees (in bits). Combined with `mem`, these implement a cap on the amount of the amount of memory that can be used.\n",
    "- `lags`: The number of lags in the Markov process being used to learn the probabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem = 200000\n",
    "d = 24\n",
    "lags = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing 2 Markov lags and 14 bits per observations means that the full context will be 28 bits long (not counting contemporaneous correlations). Given a maximum tree depth $D=24$, it is clear that some of the context will be truncated. We therefore need to permute the bits in the context to prioritise the most important ones and ensure only the least informative ones get truncated. In order to do so, the next step is to generate a permutation the context bits. \n",
    "\n",
    "As stated above, we are only demonstrating a single run of the MIC algorithm, and we choose to predict the first variable conditional on the context and the current value of the second variable. This is declared via the `var_vec` list below. To clarify the syntax, the first entry in the `var_vec` list identifies the variable to predict (1 in this case), and any subsequent entries in the list indentify contemporaneous conditioning variables (2 in our case)\n",
    "\n",
    "This will allow us to determine the value of $\\lambda^1 (x_t^1 \\mid x_t^2, \\Omega_t)$. It is important to note that to get the full MIC measurement, will need to run the algorithm again. The steps are essentially the same, and this will be covered in the second part of the demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+------------------------------------------------------+\n",
      " Predicting variable:   1\n",
      " Contemporaneous conditioning vars: \n",
      "\t[2]\n",
      " Number of conditioning lags:   2\n",
      "\n",
      "\n",
      " --------- Iteration   1 ---------\n",
      " Select lag   1 of var   1\n",
      " Correlation:  0.7443\n",
      " --------- Iteration   2 ---------\n",
      " Select lag   2 of var   2\n",
      " Correlation:  0.4978\n",
      " --------- Iteration   3 ---------\n",
      " Select lag   2 of var   1\n",
      " Correlation:  0.4974\n",
      " --------- Iteration   4 ---------\n",
      " Select lag   1 of var   2\n",
      " Correlation:  0.3625\n",
      " --------- Iteration   5 ---------\n",
      " Select contemporaneous var   2\n",
      " Correlation:  0.0899\n",
      "+------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_runs = 2\n",
    "var_vec = [1,2]  # This is the critical input, it governs the conditioning order.\n",
    "\n",
    "perm = mt.corr_perm(dat, r_vec, hp_bit_vec, var_vec, lags, d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all the elements required to train the tree. For the purpose of the demonstration the two simulated data files contain two training sets of 125,000 observations for each variable $x^1$ and $x^2$. The first set is located in the first two columns of the traing data, while the second set is located in columns 3 and 4. This division into two training sets is done in order to illustrate:\n",
    "- How to initialise a new tree on the first series\n",
    "- How to update an existing tree with further data\n",
    "\n",
    "As stated above, we are only carrying out a single run here, so we choose to learn the probabilities for the 1st model only. Once again, to get a measurement for the second model will require further runs which we do in the second part of the demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+------------------------------------------------------+\n",
      "|       Context Tree Weighting on training series      |\n",
      "+------------------------------------------------------+\n",
      "           Empty tree structure initialised\n",
      "+------------------------------------------------------+\n",
      "\t 10% complete\t   10.1220 seconds\n",
      "\t 20% complete\t   18.8578 seconds\n",
      "\t 30% complete\t   27.1562 seconds\n",
      "\t 40% complete\t   35.4127 seconds\n",
      "\t 50% complete\t   43.4386 seconds\n",
      "\t 60% complete\t   51.9838 seconds\n",
      "\t 70% complete\t   59.8614 seconds\n",
      "\t 80% complete\t   68.0705 seconds\n",
      "\t 90% complete\t   75.2379 seconds\n",
      "\t100% complete\t   82.3344 seconds\n",
      "+------------------------------------------------------+\n",
      " Total hashing time required      :    59.1277\n",
      " Average per context              : 4.7303e-04\n",
      " Total CTW updating time required :    19.7348\n",
      " Average per context              : 1.5788e-04\n",
      "+------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Load model data\n",
    "path = 'data/model_1.txt'\n",
    "sim_data = np.loadtxt(path, delimiter=\"\\t\") \n",
    "\n",
    "# Pick a tag for the tree (useful for indentifying the tree later on)\n",
    "tag = 'Model 1'\n",
    "\n",
    "# Discretise the training data. \n",
    "sim_dat1 = sim_data[:,0:2]\n",
    "data_struct = mt.bin_quant(sim_dat1,lb,ub,r_vec,'notests') # Note the 'notests' option\n",
    "data_bin = data_struct['binary_data']\n",
    "\n",
    "# Initialise a tree and train it, trying to predict the 1st variable\n",
    "var = var_vec[0]\n",
    "output = mt.train(None, data_bin, mem, lags, d, var, tag, perm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now update the tree with the second run of training data to see the difference in syntax and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "+------------------------------------------------------+\n",
      "|       Context Tree Weighting on training series      |\n",
      "+------------------------------------------------------+\n",
      "               Using \"Model 1\" structure\n",
      "+------------------------------------------------------+\n",
      "\t 10% complete\t    7.5647 seconds\n",
      "\t 20% complete\t   15.5909 seconds\n",
      "\t 30% complete\t   23.4861 seconds\n",
      "\t 40% complete\t   31.5217 seconds\n",
      "\t 50% complete\t   39.5597 seconds\n",
      "\t 60% complete\t   47.5197 seconds\n",
      "\t 70% complete\t   55.6947 seconds\n",
      "\t 80% complete\t   63.7563 seconds\n",
      "\t 90% complete\t   71.4348 seconds\n",
      "\t100% complete\t   78.3093 seconds\n",
      "+------------------------------------------------------+\n",
      " Total hashing time required      :    54.0317\n",
      " Average per context              : 4.3226e-04\n",
      " Total CTW updating time required :    20.4773\n",
      " Average per context              : 1.6382e-04\n",
      "+------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Discretise the second run of training data\n",
    "sim_dat1 = sim_data[:,2:4]\n",
    "data_struct = mt.bin_quant(sim_dat1,lb,ub,r_vec,'notests') # Note, we are not running discretisation tests\n",
    "data_bin = data_struct['binary_data']\n",
    "\n",
    "# Extract the tree from the previous output and train it again. Only the 1st argument changes\n",
    "T = output['T']\n",
    "output = mt.train(T, data_bin, mem, lags, d, var, tag, perm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how the header of the output has changed, using the tag to flag that we are updating an existing tree. We are done training the tree, let's get some descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "+------------------------------------------------------+\n",
      "               Tree diagnostics: Model 1\n",
      "+------------------------------------------------------+\n",
      " Variable 1 of 2\n",
      " Training observations:           249996\n",
      "+------------------------------------------------------+\n",
      " Memory locations allocated:      200000 nodes\n",
      " Memory usage per node:             2040 Bytes\n",
      " Memory space required:        408000000 Bytes\n",
      " Effective memory useage:      147628680 Bytes\n",
      "+------------------------------------------------------+\n",
      " Resolution:             7 bits\n",
      " Tree depth:            24 bits\n",
      " Leaf nodes:         16724 nodes\n",
      " Branch nodes:       55643 nodes\n",
      " Free nodes:        127633 nodes\n",
      "+------------------------------------------------------+\n",
      " N° of failed allocations:           0\n",
      " Maximum N° of leaf tries:           7\n",
      " Average N° of leaf tries:      1.3716\n",
      " Maximum N° of branch tries:        10\n",
      " Average N° of branch tries:    1.3506\n",
      "+------------------------------------------------------+\n",
      " Number of leaf counter rescalings: 0\n",
      "+------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# Use the built-in descriptive statistic method to get some diagnostics\n",
    "T = output['T']\n",
    "T.desc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the tree has used about 1/3 of the initial node allocation, so we have plenty of margin on memory. This will typically change if more variables are included. There is an element of trial and error to figuring out how much memory to allocated, which is why this diagnostic is useful. \n",
    "\n",
    "It is important to note that the algorithm can cope with failed node allocations (situations where the algorithm attempts to allocate a node to memory but fails), as it has a heuristic that allows it to 'skip' failed nodes, at the cost of introducing an error in the probabilities. Furthermore, because the tree implements a pruning and rollout mechanism, nodes are only allocated when they are not on a single branch path. This means that node allocation failures due to lack of memory will typically occur for very rare events\n",
    "\n",
    "Both of these mechanisms mean that memory allocation failure is graceful and the odd failure will not impair the measurement. It is nevertheless a good idea to check `T.desc()` to ensure that failed allocations are not too numerous.\n",
    "\n",
    "### Stage 2 - Scoring the empirical data with the model probabilities\n",
    "\n",
    "We have already loaded the empirical data when running the discretisation tests. For the purposes of this demonstration, we have 10 replications of 1000 observations each, in order to show the consistency of the measurement. We will therefore loop the steps required to score these series over the 10 replications. In a normal application with only one emprical dataset, this loop is of course not needed!\n",
    "\n",
    "- Discretise the empirical data into `data_stuct_emp`\n",
    "- Extract the binary data from the dictionary \n",
    "- Pass the binary data alongside the tree `T` to the score function. The function knows which variable to score as this is given in the tree.\n",
    "- Correct the score by removing the estimate of the bias (measured using the Rissanen bound correction).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Replication  0:     0.7932 secs.\n",
      "Replication  1:     0.8078 secs.\n",
      "Replication  2:     0.8371 secs.\n",
      "Replication  3:     0.8248 secs.\n",
      "Replication  4:     0.8004 secs.\n",
      "Replication  5:     0.8059 secs.\n",
      "Replication  6:     0.8500 secs.\n",
      "Replication  7:     0.8098 secs.\n",
      "Replication  8:     0.8036 secs.\n",
      "Replication  9:     0.7955 secs.\n",
      "\n",
      " Scores obtained \n",
      "    4793.87    4827.00    4794.54    4795.12    4784.41    4851.00    4788.13    4843.35    4805.88    4753.12\n"
     ]
    }
   ],
   "source": [
    "scores = np.zeros([998,10])\n",
    "\n",
    "for j in range(10):\n",
    "    loop_t = time.time()\n",
    "\n",
    "    # Discretise the data\n",
    "    k = 2*j\n",
    "    dat = emp_data[:,k:k+2]\n",
    "    data_struct_emp = mt.bin_quant(dat,lb,ub,T.r_vec,'notests')\n",
    "    data_bin_emp = data_struct_emp['binary_data']\n",
    "\n",
    "    # Score the data using the tree\n",
    "    score_struct = mt.score(T, data_bin_emp)\n",
    "\n",
    "    # Correct the measurement\n",
    "    scores[:,j] = score_struct['score'] - score_struct['bound_corr']\n",
    "\n",
    "    print('Replication {:2d}: {:10.4f} secs.'.format(j,time.time() - loop_t))\n",
    "\n",
    "flt_str = '    {:7.2f}'*10    \n",
    "print('\\n Scores obtained ')\n",
    "print(flt_str.format(*np.sum(scores,0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This provides the measurement for $\\lambda^1 (x_t^1 \\mid x_t^2, \\Omega_t)$. To complete the measurement, one also requires $\\lambda^1 (x_t^2 \\mid \\Omega_t)$. This will enable us to calculate:\n",
    "\n",
    "$$ \\lambda^1 (X) = \\sum _{t=L}^T \\left[ \\lambda^1 (x_t^1 \\mid x_t^2, \\Omega_t) + \\lambda^1 (x_t^2 \\mid \\Omega_t) \\right]$$\n",
    "\n",
    "To do this, the analysis can be re-run from `In [4]` onwards, setting `var_vec = [2]` and choosing . The resulting score for variable 2 can be added to the score above, which measures the score for variable 1, conditional on 2, thus providing the MIC for the entire system.\n",
    "\n",
    "Finally, the accuracy of the measurement can be improved by re-doing the analysis using a different conditioning order in the cross-entropy measurement. In this case this can be done by carrying out the same analysis with `var_vec = [2,1]` and `var_vec = [1]` and adding the result. This provides the following measurement:\n",
    "\n",
    "$$ \\lambda^1 (X) = \\sum _{t=L}^T \\left[ \\lambda^1 (x_t^2 \\mid x_t^1, \\Omega_t) + \\lambda^1 (x_t^1 \\mid \\Omega_t) \\right]$$\n",
    "\n",
    "In theory, the two $\\lambda^1 (X)$ measurements should be indentical, in practice they will differ by a measurement error. Averaging the will therefore improve precision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
